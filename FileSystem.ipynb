{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T11:45:55.201476Z",
     "start_time": "2020-07-12T11:45:55.116471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Users\\feelus\\Repos\\hash_sync\n"
     ]
    }
   ],
   "source": [
    "from FileSystem import *\n",
    "import os\n",
    "home_dir = os.getcwd()\n",
    "print(home_dir)\n",
    "import datetime as dt\n",
    "from datetime import *\n",
    "curtz = datetime.now().astimezone().tzinfo\n",
    "tform = '%Y-%m-%d %H-%M-%S%z'\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T11:45:55.233478Z",
     "start_time": "2020-07-12T11:45:55.204476Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_tree(obj):\n",
    "    s = myjson_dumps(nested_join(obj))\n",
    "    # проверка на кол-во строк ...\n",
    "    print(s)\n",
    "def load_snapshot(path):\n",
    "    tmp = strip_json_scomments(myjson_load(path))\n",
    "    return nested_split(tmp['root']),nested_split(tmp['errors'])\n",
    "def dump_snapshot(root,errors,path):\n",
    "    myjson_dump({\n",
    "        'errors':nested_join(errors),\n",
    "        'root':nested_join(root)\n",
    "    },path)\n",
    "def find_date_file(prefix,postfix,ls):\n",
    "    return [s[len(prefix):-len(postfix)] for s in ls if \\\n",
    "              s.startswith(prefix) and s.endswith(postfix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T11:45:55.378486Z",
     "start_time": "2020-07-12T11:45:55.236478Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "newtime_s = None\n",
    "snapshot_json = None\n",
    "oldtime_s = None\n",
    "snapshot_bak = None\n",
    "root = None\n",
    "oldroot = None\n",
    "errors = None\n",
    "olderrors = None\n",
    "patch = None\n",
    "def last_diff_dir(prefix,prefix_,exclude_dirs,load_snapshot,dump_snapshot,global_log=None):\n",
    "    emergency_dump = True\n",
    "    global newtime_s\n",
    "    global oldtime_s\n",
    "    global root\n",
    "    global oldroot\n",
    "    global errors\n",
    "    global olderrors\n",
    "    global patch\n",
    "    try:\n",
    "        os.chdir(prefix_)\n",
    "    except Exception as e:\n",
    "        if global_log:\n",
    "            with open(global_log,'a') as gl:\n",
    "                gl.write(prefix+'\\t'+'device unavailable')\n",
    "            return\n",
    "        else:\n",
    "            raise e\n",
    "    loclog = open('.files/log.txt','a')\n",
    "    globlog = open(global_log,'a') if global_log else None\n",
    "    def log(s):\n",
    "        loclog.write(str(s))\n",
    "        loclog.flush()\n",
    "        if globlog:\n",
    "            globlog.write(prefix+'\\t'+str(s))\n",
    "            globlog.flush()\n",
    "        else:\n",
    "            raise Exception(s)\n",
    "    \n",
    "    try:\n",
    "        newtime = datetime.now(curtz)\n",
    "        newtime_s = newtime.strftime(tform)\n",
    "        snapshot_json = '.files/last_snapshot '+newtime_s+'.json'\n",
    "        def find_date_file(prefix,postfix,ls):\n",
    "            return [s[len(prefix):-len(postfix)] for s in ls if \\\n",
    "                      s.startswith(prefix) and s.endswith(postfix)]\n",
    "        if '.files' in os.listdir('.'):\n",
    "            ls = os.listdir('.files\\\\')\n",
    "            oldtime_list = find_date_file('last_snapshot ','.bak',ls)\n",
    "            assert len(oldtime_list)<=1\n",
    "            if len(oldtime_list)==1:\n",
    "                oldtime_s = oldtime_list[0]\n",
    "                snapshot_bak = '.files/last_snapshot '+oldtime_s+'.bak'\n",
    "\n",
    "                oldroot,olderrors = load_snapshot(snapshot_bak) # <----\n",
    "                newtime_list = find_date_file('last_snapshot ','.json',ls)\n",
    "                assert len(newtime_list)<=1\n",
    "                if len(newtime_list)==1:\n",
    "                    print('fast recovery')\n",
    "                    # сканируем-пересчитываем на основе .json\n",
    "                    # затем удаляем его и сохраняем новый\n",
    "                    newtime_s = newtime_list[0]\n",
    "                    snapshot_json = '.files/last_snapshot '+newtime_s+'.json'\n",
    "\n",
    "                    root,errors = load_snapshot(snapshot_json) # <----\n",
    "                    #root,errors = scan(prefix_,exclude_dirs)\n",
    "                    #calc_hashes(root,errors,oldnewroot,prefix)\n",
    "\n",
    "                    #os.remove(oldsnapshot_json)\n",
    "                    #dump_snapshot(root,errors,snapshot_json) # ---->\n",
    "                else:\n",
    "                    print('recovery')\n",
    "                    # сканируем-пересчитываем на основе .bak\n",
    "                    # затем сохраняем новый\n",
    "                    root,errors = scan(prefix_,exclude_dirs)\n",
    "                    calc_hashes(root,errors,oldroot,prefix)\n",
    "\n",
    "                    dump_snapshot(root,errors,snapshot_json) # ---->\n",
    "            else:\n",
    "                print('simple update')\n",
    "                # сканируем-пересчитываем на основе json\n",
    "                # затем переименовываем его в .bak и сохраняем новый\n",
    "                oldtime_list = find_date_file('last_snapshot ','.json',ls)\n",
    "                assert len(oldtime_list)==1\n",
    "                oldtime_s = oldtime_list[0]\n",
    "                snapshot_bak = '.files/last_snapshot '+oldtime_s+'.bak'\n",
    "\n",
    "                oldroot,olderrors = load_snapshot('.files/last_snapshot '+oldtime_s+'.json') # <----\n",
    "                root,errors = scan(prefix_,exclude_dirs)\n",
    "                calc_hashes(root,errors,oldroot,prefix)\n",
    "\n",
    "                os.rename('.files/last_snapshot '+oldtime_s+'.json',snapshot_bak)\n",
    "                dump_snapshot(root,errors,snapshot_json) # ---->\n",
    "        else:\n",
    "            print('create all')\n",
    "            # записываем пустое дерево в .bak (дата на минуту раньше текущей)\n",
    "            # сканируем-пересчитываем на основе .bak\n",
    "            # затем сохраняем новый\n",
    "            os.mkdir('.files')\n",
    "            oldtime_s = (newtime - timedelta(minutes=1)).strftime(tform)\n",
    "            snapshot_bak = '.files/last_snapshot '+oldtime_s+'.bak'\n",
    "            oldroot = {}\n",
    "            root,errors = scan(prefix_,exclude_dirs)\n",
    "            calc_hashes(root,errors,oldroot,prefix)\n",
    "\n",
    "            dump_snapshot(oldroot,{},snapshot_bak) # ---->\n",
    "            dump_snapshot(root,errors,snapshot_json)\n",
    "    except BaseException as e:\n",
    "        log(Exception('scan:',e))\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        oldroot_d = oldroot#{k:v for k,v in oldroot.items() if k!='__scan_errors__'}\n",
    "        root_d = root#{k:v for k,v in root.items() if k!='__scan_errors__'}\n",
    "        modified,old,new,strict_old,strict_new,touched = path_diff(oldroot_d,root_d)\n",
    "        assert set(old)&set(strict_old) == set()\n",
    "        assert set(new)&set(strict_new) == set()\n",
    "        moved,old_dirs,new_dirs,old,new = hash_diff(old,new)\n",
    "        assert set(old)&set(strict_old) == set()\n",
    "        assert set(new)&set(strict_new) == set()\n",
    "        e_modified,e_old,e_new,e_strict_old,e_strict_new,e_touched = path_diff(olderrors,errors)\n",
    "\n",
    "        patch = {\n",
    "            'errors':path_patch_compress(e_modified,e_old,e_new,e_strict_old,e_strict_new,e_touched),\n",
    "            'root':hash_patch_compress(modified,moved,old_dirs,new_dirs,\n",
    "                                  {**old,**strict_old},{**new,**strict_new},touched)\n",
    "        }\n",
    "\n",
    "        modified_d,moved_d,old_dirs_d,new_dirs_d,old_d,new_d,touched_d = \\\n",
    "            hash_patch_uncompress(patch['root'])\n",
    "        newoldroot = hash_back_patch(root_d,modified_d,moved_d,old_dirs_d,new_dirs_d,\n",
    "                              old_d,new_d,touched_d)\n",
    "        assert oldroot_d==newoldroot\n",
    "\n",
    "        e_modified_d,e_old_d,e_new_d,e_strict_old_d,e_strict_new_d,e_touched_d = \\\n",
    "            path_patch_uncompress(patch['errors'])\n",
    "        newerrors = path_patch(olderrors,e_modified_d,\n",
    "                {**e_old_d,**e_strict_old_d},{**e_new_d,**e_strict_new_d}, e_touched_d)\n",
    "        assert errors==newerrors\n",
    "        \n",
    "    except BaseException as e:\n",
    "        if emergency_dump:\n",
    "            print('exception catched, writing \"exception_dump.json\"')\n",
    "            with open('.files/exception_dump.json','w') as file:\n",
    "                json.dump({'olderrors':olderrors,'errors':errors,'oldroot':oldroot,\n",
    "                           'root':root},      file)\n",
    "        log(Exception('diff:',e))\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        myjson_dump(patch,'.files/patch '+oldtime_s+' to '+newtime_s+'.json')\n",
    "        if find_date_file('first_snapshot ','.json',ls):\n",
    "            os.remove(snapshot_bak)\n",
    "        else:\n",
    "            os.rename(snapshot_bak,'.files/first_snapshot '+oldtime_s+'.json',)\n",
    "    except BaseException as e:\n",
    "        log(Exception('scan:',e))\n",
    "        return\n",
    "        \n",
    "    loclog.close()\n",
    "    if globlog: globlog.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T14:20:40.756278Z",
     "start_time": "2020-07-11T14:20:07.131355Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast recovery\n",
      "--- ITERATION ---\n",
      "--- ITERATION ---\n",
      "--- FINAL ITERATION ---\n",
      "start writing\n",
      "writed .files/patch 2020-07-10 19-23-44+0300 to 2020-07-11 16-05-10+0300.json\n"
     ]
    }
   ],
   "source": [
    "exclude_dirs = {r'D:\\Users\\feelus\\YandexDisk',r'D:\\$RECYCLE.BIN'}\n",
    "prefix = 'D:'\n",
    "prefix_ = prefix+'\\\\'\n",
    "last_diff_dir(prefix,prefix_,exclude_dirs,load_snapshot,dump_snapshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T14:32:35.516160Z",
     "start_time": "2020-07-11T14:21:10.155960Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple update\n",
      "141 GB scanned - completed\n",
      "141 GB calculated, 1 GB calculated (99% cached)- completed\n",
      "--- ITERATION ---\n",
      "--- ITERATION ---\n",
      "--- FINAL ITERATION ---\n",
      "start writing\n",
      "writed .files/patch 2020-07-10 20-46-48+0300 to 2020-07-11 17-21-10+0300.json\n"
     ]
    }
   ],
   "source": [
    "exclude_dirs = {r'C:\\$RECYCLE.BIN'}\n",
    "prefix = 'C:'\n",
    "prefix_ = prefix+'\\\\'\n",
    "def en_load_snapshot(path):\n",
    "    with open(path,'r') as file:\n",
    "        tmp = strip_json_scomments(json.load(file))\n",
    "    return nested_split(tmp['root']),nested_split(tmp['errors'])\n",
    "def en_dump_snapshot(root,errors,path):\n",
    "    with open(path,'w') as file:\n",
    "        json.dump({\n",
    "            'errors':nested_join(errors),\n",
    "            'root':nested_join(root)\n",
    "        },file,indent='\\t')\n",
    "\n",
    "last_diff_dir(prefix,prefix_,exclude_dirs,en_load_snapshot,en_dump_snapshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T14:33:49.314381Z",
     "start_time": "2020-07-11T14:32:35.519160Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple update\n",
      "207 GB scanned - completed\n",
      "207 GB calculated, 0 GB calculated (99% cached)- completed\n",
      "start writing\n",
      "writed .files/last_snapshot 2020-07-11 17-32-35+0300.json\n",
      "--- ITERATION ---\n",
      "--- ITERATION ---\n",
      "--- FINAL ITERATION ---\n",
      "start writing\n",
      "writed .files/patch 2020-07-10 20-59-29+0300 to 2020-07-11 17-32-35+0300.json\n"
     ]
    }
   ],
   "source": [
    "exclude_dirs = {}\n",
    "prefix = r'D:\\Users\\feelus\\YandexDisk'\n",
    "prefix_ = prefix+'\\\\'\n",
    "last_diff_dir(prefix,prefix_,exclude_dirs,load_snapshot,dump_snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T18:00:46.854603Z",
     "start_time": "2020-07-10T18:00:46.644591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(222633560483, 12161, 133130, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_stat(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T18:00:48.311687Z",
     "start_time": "2020-07-10T18:00:46.857604Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple update\n",
      "343 GB scanned - completed\n",
      "343 GB calculated, 0 GB calculated (99% cached)- completed\n",
      "start writing\n",
      "writed .files/last_snapshot 2020-07-10 21-00-46+0300.json\n",
      "--- ITERATION ---\n",
      "--- FINAL ITERATION ---\n",
      "start writing\n",
      "writed .files/patch 2020-07-10 00-29-28+0300 to 2020-07-10 21-00-46+0300.json\n"
     ]
    }
   ],
   "source": [
    "exclude_dirs = {r'H:\\$RECYCLE.BIN'}\n",
    "prefix = 'H:'\n",
    "prefix_ = prefix+'\\\\'\n",
    "last_diff_dir(prefix,prefix_,exclude_dirs,load_snapshot,dump_snapshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T18:13:19.728665Z",
     "start_time": "2020-07-10T18:00:48.317687Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple update\n",
      "330 GB scanned - completed\n",
      "330 GB calculated, 0 GB calculated (99% cached)- completed\n",
      "start writing\n",
      "writed .files/last_snapshot 2020-07-10 21-00-48+0300.json\n",
      "--- ITERATION ---\n",
      "--- FINAL ITERATION ---\n",
      "start writing\n",
      "writed .files/patch 2020-07-10 00-29-30+0300 to 2020-07-10 21-00-48+0300.json\n"
     ]
    }
   ],
   "source": [
    "exclude_dirs = {r'I:\\$RECYCLE.BIN'}\n",
    "prefix = 'I:'\n",
    "prefix_ = prefix+'\\\\'\n",
    "last_diff_dir(prefix,prefix_,exclude_dirs,load_snapshot,dump_snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.787160Z",
     "start_time": "2020-07-10T16:23:43.922Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"shutdown /s /t 1\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.792160Z",
     "start_time": "2020-07-10T16:23:43.926Z"
    }
   },
   "outputs": [],
   "source": [
    "raise BaseException()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.804161Z",
     "start_time": "2020-07-10T16:23:43.931Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "myjson_dumps({chr(0):0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.806161Z",
     "start_time": "2020-07-10T16:23:43.939Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'\\x00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.807161Z",
     "start_time": "2020-07-10T16:23:43.945Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(r'.files/last_snapshot 2019-11-18 14-25-23+3000.bak','r') as file:\n",
    "    tmp = tree_load(json.load(file))\n",
    "    \n",
    "del tmp['root']['Windows']['System32']['LogFiles']['HTTPERR']['httperr1.log']\n",
    "\n",
    "with open(r'.files/last_snapshot 2019-11-18 14-25-23+3000.bak','w') as file:\n",
    "    json.dump(tree_dump(tmp),file,indent='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.808161Z",
     "start_time": "2020-07-10T16:23:43.953Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from copy import *\n",
    "\n",
    "len(old)\n",
    "old_d = {}#deepcopy(old)\n",
    "keys = [k for k in old.keys()]\n",
    "for k in keys:#[2554:]:\n",
    "    old_d[k]=deepcopy(old[k])\n",
    "print(len(old_d))\n",
    "\n",
    "len(new)\n",
    "new_d = {}#deepcopy(old)\n",
    "keys = [k for k in new.keys()]\n",
    "for k in keys:#[3164:-1]:\n",
    "    new_d[k]=deepcopy(new[k])\n",
    "print(len(new_d))\n",
    "\n",
    "#print(myjson_dumps(path_patch_dump({},old_d,new_d,{},{})))\n",
    "\n",
    "r = hash_diff(old_d,new_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.810161Z",
     "start_time": "2020-07-10T16:23:43.957Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "old_root = myjson_load(r'D:\\.files\\111.json')\n",
    "root = myjson_load(r'D:\\.files\\222.json')\n",
    "\n",
    "#root = scan('D:\\\\',{r'D:\\Users\\feelus\\YandexDisk',r'D:\\$RECYCLE.BIN'})\n",
    "#calc_hashes(root,old_root,'D:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.811161Z",
     "start_time": "2020-07-10T16:23:43.962Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "oldroot_d = oldroot#{k:v for k,v in oldroot.items() if k!='__scan_errors__'}\n",
    "root_d = root#{k:v for k,v in root.items() if k!='__scan_errors__'}\n",
    "modified,old,new,strict_old,strict_new,touched = path_diff(oldroot_d,root_d)\n",
    "assert set(old)&set(strict_old) == set()\n",
    "assert set(new)&set(strict_new) == set()\n",
    "moved,old_dirs,new_dirs,old,new = hash_diff(old,new)\n",
    "assert set(old)&set(strict_old) == set()\n",
    "assert set(new)&set(strict_new) == set()\n",
    "\n",
    "newoldroot = hash_back_patch(root_d,modified,moved,old_dirs,new_dirs,\n",
    "                      {**old,**strict_old},{**new,**strict_new},touched)\n",
    "#first_diff(root_d,new_root_d)\n",
    "assert oldroot_d==newoldroot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.812162Z",
     "start_time": "2020-07-10T16:23:43.966Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    old = {\n",
    "        ('a','b'):[1,1,'1']\n",
    "    }\n",
    "    new = {\n",
    "        ('b','c'):[2,2,'2']\n",
    "    }\n",
    "if 0:\n",
    "    old = {\n",
    "        ('a','b'):[1,1,'1']\n",
    "    }\n",
    "    new = {\n",
    "        ('b','c'):[2,2,'1']\n",
    "    }\n",
    "if 0:\n",
    "    old = {\n",
    "        ('a','b'):[1,1,'1'],\n",
    "        ('a','c'):[1,1,'1'],\n",
    "    }\n",
    "    new = {\n",
    "        ('b','c'):[2,2,'1']\n",
    "    }\n",
    "if 1:\n",
    "    old = {\n",
    "        ('a','b'):[1,1,'1'],\n",
    "        ('a','c'):[1,1,'1'],\n",
    "    }\n",
    "    new = {\n",
    "        ('b','c'):[2,2,'1'],\n",
    "        ('b','d'):[2,2,'1'],\n",
    "    }\n",
    "r = hash_diff(old,new)\n",
    "\n",
    "print('moved',r[0])\n",
    "print('old',r[1])\n",
    "print('new',r[2])\n",
    "print('old1',r[3])\n",
    "print('new1',r[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.813162Z",
     "start_time": "2020-07-10T16:23:43.971Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "oldroot['.files']['patch 2019-11-24 02-40-04+0300 to 2019-11-25 00-37-04+0300.json']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.814162Z",
     "start_time": "2020-07-10T16:23:43.976Z"
    }
   },
   "outputs": [],
   "source": [
    "exclude_dirs = {r'D:\\Users\\feelus\\YandexDisk',r'D:\\$RECYCLE.BIN'}\n",
    "prefix = 'D:'\n",
    "prefix_ = prefix+'\\\\'\n",
    "os.chdir(prefix_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.815162Z",
     "start_time": "2020-07-10T16:23:43.980Z"
    }
   },
   "outputs": [],
   "source": [
    "oldroot,olderrors = load_snapshot('.files/2019-12-08 01-50-34+0300 snapshot.json');\n",
    "root,errors = load_snapshot('.files/2019-12-09 00-18-35+0300 init_snapshot.json');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.816162Z",
     "start_time": "2020-07-10T16:23:43.984Z"
    }
   },
   "outputs": [],
   "source": [
    "root['Users']['feelus']['AppData']['Roaming']['Typora']['themes']['old-themes'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.817162Z",
     "start_time": "2020-07-10T16:23:43.987Z"
    }
   },
   "outputs": [],
   "source": [
    "kkk = {\n",
    "    'github.css', \n",
    "    \n",
    "}\n",
    "oldroot_d = {k:v for k,v in oldroot['Users']['feelus']['AppData']['Roaming']['Typora']['themes']['old-themes'].items() if k in kkk}\n",
    "root_d = {k:v for k,v in root['Users']['feelus']['AppData']['Roaming']['Typora']['themes']['old-themes'].items() if k in kkk}\n",
    "oldroot_d = oldroot\n",
    "root_d = root\n",
    "#print(oldroot_d)\n",
    "#print(root_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.818162Z",
     "start_time": "2020-07-10T16:23:43.990Z"
    }
   },
   "outputs": [],
   "source": [
    "modified,old,new,strict_old,strict_new,touched = path_diff(oldroot_d,root_d)\n",
    "assert set(old)&set(strict_old) == set()\n",
    "assert set(new)&set(strict_new) == set()\n",
    "moved,old_dirs,new_dirs,old,new = hash_diff(old,new)\n",
    "assert set(old)&set(strict_old) == set()\n",
    "assert set(new)&set(strict_new) == set()\n",
    "#print(modified)\n",
    "#print(touched)\n",
    "#print(old)\n",
    "#print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.819162Z",
     "start_time": "2020-07-10T16:23:43.993Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "newoldroot = hash_back_patch(root_d,modified,moved,old_dirs,new_dirs,\n",
    "                      {**old,**strict_old},{**new,**strict_new},touched)\n",
    "#first_diff(root_d,new_root_d)\n",
    "assert oldroot_d==newoldroot\n",
    "\n",
    "e_modified,e_old,e_new,e_strict_old,e_strict_new,e_touched = path_diff(olderrors,errors)\n",
    "newerrors = path_patch(olderrors,e_modified,\n",
    "                       {**e_old,**e_strict_old},{**e_new,**e_strict_new}, e_touched)\n",
    "assert errors==newerrors\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.821162Z",
     "start_time": "2020-07-10T16:23:43.996Z"
    }
   },
   "outputs": [],
   "source": [
    "patch_name = '.files/2019-12-08 01-50-34+0300 to 2019-12-09 00-18-35+0300 patch.json'\n",
    "myjson_dump({\n",
    "    'errors':path_patch_dump(e_modified,e_old,e_new,e_strict_old,e_strict_new,e_touched),\n",
    "    'root':hash_patch_dump(modified,moved,old_dirs,new_dirs,\n",
    "                          {**old,**strict_old},{**new,**strict_new},touched)\n",
    "},patch_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.822162Z",
     "start_time": "2020-07-10T16:23:44.014Z"
    }
   },
   "outputs": [],
   "source": [
    "doc = myjson_load('D://.files/patch 2020-07-05 00-25-06+0300 to 2020-07-08 00-15-44+0300.json')\n",
    "hp = doc['root']\n",
    "tmp = pathlist2moved(moved2pathlist(hp['moved']))\n",
    "moved = hp['moved']\n",
    "hp['moved'] = moved2pathlist(hp['moved'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.823162Z",
     "start_time": "2020-07-10T16:23:44.017Z"
    }
   },
   "outputs": [],
   "source": [
    "x1=set()#moved\n",
    "x2=set()#tmp\n",
    "for i in range(len(tmp)):\n",
    "    x1.add(tuple(moved[i]))\n",
    "    x2.add(tuple(tmp[i]))\n",
    "x1==x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.824162Z",
     "start_time": "2020-07-10T16:23:44.020Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = action2tree(hp)\n",
    "tmp2 = tree2action(tmp)\n",
    "tmp2==hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.831163Z",
     "start_time": "2020-07-10T16:23:44.023Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp3 = nested_join(tmp,'',lambda x: not x.startswith('/'),lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.832163Z",
     "start_time": "2020-07-10T16:23:44.026Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp==nested_split(tmp3,'/',False,lambda x: not x.startswith('/'),lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T14:08:29.690848Z",
     "start_time": "2020-07-10T14:08:29.646846Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.833163Z",
     "start_time": "2020-07-10T16:23:44.032Z"
    }
   },
   "outputs": [],
   "source": [
    "test = {'/f':{'new':\"1594120574.2637675 32500327884 d9d08e1a0837cc42112fb62da4a1211c\"}}\n",
    "statistics(test,300_000_000)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.834163Z",
     "start_time": "2020-07-10T16:23:44.036Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir('D://.files')\n",
    "statistics(tmp3,300_000_000)\n",
    "myjson_dump(tmp3,'test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.835163Z",
     "start_time": "2020-07-10T16:23:44.041Z"
    }
   },
   "outputs": [],
   "source": [
    "nested_split(nested_join({\n",
    "    'x':{\n",
    "        'y':[1,2,'3'],\n",
    "        'z':[1,2,'3'],\n",
    "    }\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.836163Z",
     "start_time": "2020-07-10T16:23:44.045Z"
    }
   },
   "outputs": [],
   "source": [
    "'/a/b/c'.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T16:28:44.837163Z",
     "start_time": "2020-07-10T16:23:44.048Z"
    }
   },
   "outputs": [],
   "source": [
    "y=None\n",
    "def foo(a=1,b=2,x=y):\n",
    "    print(y(73))\n",
    "def yy(x):\n",
    "    return x\n",
    "y=yy\n",
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T11:46:09.479292Z",
     "start_time": "2020-07-12T11:46:09.469292Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\\\.files\\\\')\n",
    "ls = os.listdir('.')\n",
    "ols = []#find_date_file('patch ','.json',ls)\n",
    "for s in ols:\n",
    "    os.rename('patch '+s+'.json',s+' patch.json',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T11:46:10.073326Z",
     "start_time": "2020-07-12T11:46:10.052325Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls = os.listdir('.')\n",
    "ols = find_date_file('',' patch.json',ls)\n",
    "def en_load_snapshot(path):\n",
    "    with open(path,'r') as file:\n",
    "        tmp = strip_json_scomments(json.load(file))\n",
    "    return nested_split(tmp['root']),nested_split(tmp['errors'])\n",
    "def en_dump_snapshot(root,errors,path):\n",
    "    with open(path,'w') as file:\n",
    "        json.dump({\n",
    "            'errors':nested_join(errors),\n",
    "            'root':nested_join(root)\n",
    "        },file,indent='\\t')\n",
    "\n",
    "for s in []:#ols:\n",
    "    with open(s+' patch.json','r') as file:\n",
    "        patch = json.load(file)\n",
    "\n",
    "    hp = patch['errors']\n",
    "    #hp['moved'] = moved2pathlist(hp['moved'])\n",
    "    hp = action2tree(hp)\n",
    "    hp = nested_join(hp,'',lambda x: not x.startswith('/'),lambda x:x)\n",
    "    statistics(hp,300_000_000)\n",
    "    patch['errors']=hp\n",
    "\n",
    "    hp = patch['root']\n",
    "    hp['moved'] = moved2pathlist(hp['moved'])\n",
    "    hp = action2tree(hp)\n",
    "    hp = nested_join(hp,'',lambda x: not x.startswith('/'),lambda x:x)\n",
    "    statistics(hp,300_000_000)\n",
    "    patch['root']=hp\n",
    "\n",
    "    print('patch '+s+'.json')\n",
    "    myjson_dump(patch,'patch '+s+'.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T11:46:10.574355Z",
     "start_time": "2020-07-12T11:46:10.558354Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_list(path='.',start = None):\n",
    "    ls = os.listdir(path)\n",
    "    ols = find_date_file('patch ','.json',ls)\n",
    "    r = {}\n",
    "    l = {}\n",
    "    for s in ols:\n",
    "        f,t = s.split(' to ')\n",
    "        r[f]=t\n",
    "        l[t]=f\n",
    "    if not start:\n",
    "        start = next(iter(r))\n",
    "    lst = [start]\n",
    "    while lst[0] in l:\n",
    "        cur = lst[0]\n",
    "        lst.insert(0,l[cur])\n",
    "        del r[l[cur]]\n",
    "        del l[cur]\n",
    "    while lst[-1] in r:\n",
    "        cur = lst[-1]\n",
    "        lst.append(r[cur])\n",
    "        del l[r[cur]]\n",
    "        del r[cur]\n",
    "    #assert len(l)==len(r)\n",
    "    if len(r)>0:\n",
    "        print('осталось',len(r),'переходов')\n",
    "    return lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T11:46:11.343399Z",
     "start_time": "2020-07-12T11:46:11.323398Z"
    }
   },
   "outputs": [],
   "source": [
    "def patch_chain(lst,frm,to,in_snapshot):\n",
    "    if type(frm)!=int:\n",
    "        frm=lst.index(frm)\n",
    "    assert frm>=0 and frm<len(lst)\n",
    "    if type(to)!=int:\n",
    "        to=lst.index(to)\n",
    "    assert to>=0 and to<len(lst)\n",
    "    errors = in_snapshot['errors']\n",
    "    root = in_snapshot['root']\n",
    "    print(frm,to)\n",
    "    if frm<to: # to right\n",
    "        for i in range(frm,to):\n",
    "            path = 'patch '+lst[i]+' to '+lst[i+1]+'.json'\n",
    "            print(path)\n",
    "            patch = myjson_load(path)\n",
    "            \n",
    "            e_modified_d,e_old_d,e_new_d,e_strict_old_d,e_strict_new_d,e_touched_d = \\\n",
    "                path_patch_uncompress(patch['errors'])\n",
    "            errors = path_patch(errors,e_modified_d,\n",
    "                    {**e_old_d,**e_strict_old_d},{**e_new_d,**e_strict_new_d}, e_touched_d)\n",
    "            \n",
    "            modified_d,moved_d,old_dirs_d,new_dirs_d,old_d,new_d,touched_d = \\\n",
    "                hash_patch_uncompress(patch['root'])\n",
    "            root = hash_patch(root,modified_d,moved_d,old_dirs_d,new_dirs_d,\n",
    "                                  old_d,new_d,touched_d)\n",
    "\n",
    "    elif frm>to: # to left\n",
    "        for i in range(frm,to,-1):\n",
    "            path = 'patch '+lst[i-1]+' to '+lst[i]+'.json'\n",
    "            print('back',path)\n",
    "            patch = myjson_load(path)\n",
    "            \n",
    "            e_modified_d,e_old_d,e_new_d,e_strict_old_d,e_strict_new_d,e_touched_d = \\\n",
    "                path_patch_uncompress(patch['errors'])\n",
    "            errors = path_back_patch(errors,e_modified_d,\n",
    "                    {**e_old_d,**e_strict_old_d},{**e_new_d,**e_strict_new_d}, e_touched_d)\n",
    "            \n",
    "            modified_d,moved_d,old_dirs_d,new_dirs_d,old_d,new_d,touched_d = \\\n",
    "                hash_patch_uncompress(patch['root'])\n",
    "            root = hash_back_patch(root,modified_d,moved_d,old_dirs_d,new_dirs_d,\n",
    "                                  old_d,new_d,touched_d)\n",
    "    return {'errors':errors,'root':root}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T11:46:13.668532Z",
     "start_time": "2020-07-12T11:46:13.644531Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019-11-18 14-25-23+3000',\n",
       " '2019-11-21 11-37-35+0300',\n",
       " '2019-11-21 12-24-38+0300',\n",
       " '2019-11-22 01-08-21+0300',\n",
       " '2019-11-23 00-09-47+0300',\n",
       " '2019-11-24 02-43-50+0300',\n",
       " '2019-11-25 00-40-57+0300',\n",
       " '2019-11-25 23-33-25+0300',\n",
       " '2019-11-30 01-52-54+0300',\n",
       " '2019-12-03 01-55-50+0300',\n",
       " '2019-12-06 01-32-24+0300',\n",
       " '2019-12-06 16-07-50+0300',\n",
       " '2019-12-07 01-23-41+0300',\n",
       " '2019-12-08 01-54-08+0300',\n",
       " '2019-12-09 00-32-42+0300',\n",
       " '2019-12-10 00-54-49+0300',\n",
       " '2019-12-11 00-31-21+0300',\n",
       " '2019-12-12 00-14-30+0300',\n",
       " '2019-12-12 23-17-39+0300',\n",
       " '2019-12-14 00-48-15+0300',\n",
       " '2019-12-15 01-21-23+0300',\n",
       " '2019-12-16 00-50-13+0300',\n",
       " '2019-12-17 00-43-01+0300',\n",
       " '2019-12-18 01-34-24+0300',\n",
       " '2019-12-20 03-19-32+0300',\n",
       " '2019-12-21 03-25-42+0300',\n",
       " '2019-12-23 02-12-07+0300',\n",
       " '2019-12-23 23-34-10+0300',\n",
       " '2019-12-26 00-49-59+0300',\n",
       " '2019-12-28 00-48-04+0300',\n",
       " '2019-12-30 01-29-03+0300',\n",
       " '2019-12-31 01-35-48+0300',\n",
       " '2020-01-02 02-44-55+0300',\n",
       " '2020-01-05 02-45-25+0300',\n",
       " '2020-01-06 03-34-16+0300',\n",
       " '2020-01-07 03-25-47+0300',\n",
       " '2020-01-08 03-27-50+0300',\n",
       " '2020-01-10 04-29-16+0300',\n",
       " '2020-01-11 04-26-19+0300',\n",
       " '2020-01-13 03-45-42+0300',\n",
       " '2020-01-16 03-47-25+0300',\n",
       " '2020-01-18 02-02-39+0300',\n",
       " '2020-01-19 02-17-03+0300',\n",
       " '2020-01-21 21-44-18+0300',\n",
       " '2020-01-22 22-03-02+0300',\n",
       " '2020-01-26 00-58-18+0300',\n",
       " '2020-01-28 01-15-39+0300',\n",
       " '2020-01-30 00-27-26+0300',\n",
       " '2020-01-31 23-22-56+0300',\n",
       " '2020-02-05 02-18-31+0300',\n",
       " '2020-02-09 01-57-53+0300',\n",
       " '2020-02-18 01-56-47+0300',\n",
       " '2020-02-29 01-09-35+0300',\n",
       " '2020-03-01 00-33-31+0300',\n",
       " '2020-03-07 00-44-24+0300',\n",
       " '2020-03-09 01-00-43+0300',\n",
       " '2020-03-12 01-38-32+0300',\n",
       " '2020-03-13 01-20-08+0300',\n",
       " '2020-03-14 02-09-09+0300',\n",
       " '2020-03-21 07-28-43+0300',\n",
       " '2020-03-21 20-30-08+0300',\n",
       " '2020-03-21 22-05-26+0300',\n",
       " '2020-03-23 23-00-35+0300',\n",
       " '2020-03-25 04-41-33+0300',\n",
       " '2020-03-30 00-12-08+0300',\n",
       " '2020-04-01 01-32-27+0300',\n",
       " '2020-04-02 01-21-34+0300',\n",
       " '2020-04-03 00-38-43+0300',\n",
       " '2020-04-06 00-53-40+0300',\n",
       " '2020-04-08 01-08-43+0300',\n",
       " '2020-04-12 03-14-31+0300',\n",
       " '2020-04-18 01-07-42+0300',\n",
       " '2020-04-22 02-51-56+0300',\n",
       " '2020-04-24 00-38-55+0300',\n",
       " '2020-05-11 01-22-01+0300',\n",
       " '2020-05-31 11-40-04+0300',\n",
       " '2020-07-02 23-29-48+0300',\n",
       " '2020-07-05 00-35-40+0300',\n",
       " '2020-07-08 00-25-23+0300',\n",
       " '2020-07-10 00-15-35+0300',\n",
       " '2020-07-10 20-46-48+0300',\n",
       " '2020-07-11 17-21-10+0300']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r'C:\\\\.files\\\\')\n",
    "lst = check_list()\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T11:56:43.702568Z",
     "start_time": "2020-07-12T11:56:34.635049Z"
    }
   },
   "outputs": [],
   "source": [
    "def en_load_snapshot(path):\n",
    "    with open(path,'r') as file:\n",
    "        tmp = strip_json_scomments(json.load(file))\n",
    "    return nested_split(tmp['root']),nested_split(tmp['errors'])\n",
    "root,errs = en_load_snapshot('last_snapshot 2020-07-10 00-15-35+0300.bak1')\n",
    "snap79 = {'errors':errs,'root':root}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T11:57:07.838948Z",
     "start_time": "2020-07-12T11:56:45.261657Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 81\n",
      "patch 2020-07-10 00-15-35+0300 to 2020-07-10 20-46-48+0300.json\n",
      "patch 2020-07-10 20-46-48+0300 to 2020-07-11 17-21-10+0300.json\n",
      "('.files', 'last_snapshot 2020-07-10 00-15-35+0300.json') ('.files', 'last_snapshot 2020-07-10 00-15-35+0300.bak1')\n"
     ]
    }
   ],
   "source": [
    "snap81_1 = patch_chain(lst,'2020-07-10 00-15-35+0300','2020-07-11 17-21-10+0300',snap79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T11:33:52.640148Z",
     "start_time": "2020-07-12T11:33:41.648519Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 78\n",
      "back patch 2020-07-08 00-25-23+0300 to 2020-07-10 00-15-35+0300.json\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Р’РѕСЃСЃС‚Р°РЅРѕРІР»РµРЅРёРµ СЃРµСЂРІРёСЃР° РѕР±РЅРѕРІР»РµРЅРёР№ РЇРЅРґРµРєСЃ.Р‘СЂР°СѓР·РµСЂР°.job'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b5a05792572d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msnap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpatch_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2020-07-10 00-15-35+0300'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2020-07-08 00-25-23+0300'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0min_snap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-5774bfbfb29c>\u001b[0m in \u001b[0;36mpatch_chain\u001b[1;34m(lst, frm, to, in_snapshot)\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[0mhash_patch_uncompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'root'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             root = hash_back_patch(root,modified_d,moved_d,old_dirs_d,new_dirs_d,\n\u001b[1;32m---> 41\u001b[1;33m                                   old_d,new_d,touched_d)\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'errors'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'root'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\hash_sync\\FileSystem.py\u001b[0m in \u001b[0;36mhash_back_patch\u001b[1;34m(root, in_modified, in_moved, in_old_dirs, in_new_dirs, in_old, in_new, in_touched)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfrom_p\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mto_p\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfrom_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mto_obj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0min_moved\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                 \u001b[0mmoved\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_p\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfrom_p\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mto_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfrom_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1102\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mhash_patch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodified\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmoved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0min_new_dirs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0min_old_dirs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0min_new\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0min_old\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtouched\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Repos\\hash_sync\\FileSystem.py\u001b[0m in \u001b[0;36mhash_patch\u001b[1;34m(old_root, modified, moved, old_dirs, new_dirs, old, new, touched)\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodified\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m                 \u001b[0mparent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_subtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1055\u001b[1;33m                 \u001b[1;32massert\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mold_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1056\u001b[0m                 \u001b[0mparent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtouched\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Р’РѕСЃСЃС‚Р°РЅРѕРІР»РµРЅРёРµ СЃРµСЂРІРёСЃР° РѕР±РЅРѕРІР»РµРЅРёР№ РЇРЅРґРµРєСЃ.Р‘СЂР°СѓР·РµСЂР°.job'"
     ]
    }
   ],
   "source": [
    "snap78 = patch_chain(lst,'2020-07-10 00-15-35+0300','2020-07-08 00-25-23+0300',snap79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T11:57:55.537677Z",
     "start_time": "2020-07-12T11:57:45.676113Z"
    }
   },
   "outputs": [],
   "source": [
    "def en_load_snapshot(path):\n",
    "    with open(path,'r') as file:\n",
    "        tmp = strip_json_scomments(json.load(file))\n",
    "    return nested_split(tmp['root']),nested_split(tmp['errors'])\n",
    "root,errs = en_load_snapshot('last_snapshot 2020-07-11 17-21-10+0300.json')\n",
    "snap81 = {'errors':errs,'root':root}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T11:58:12.349638Z",
     "start_time": "2020-07-12T11:58:03.132111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 80\n",
      "back patch 2020-07-10 20-46-48+0300 to 2020-07-11 17-21-10+0300.json\n",
      "('.files', 'last_snapshot 2020-07-10 00-15-35+0300.bak1') ('.files', 'last_snapshot 2020-07-10 00-15-35+0300.json')\n"
     ]
    }
   ],
   "source": [
    "snap80_2 = patch_chain(lst,'2020-07-11 17-21-10+0300','2020-07-10 20-46-48+0300',snap81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T12:00:03.866017Z",
     "start_time": "2020-07-12T11:59:38.502566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 79\n",
      "back patch 2020-07-10 20-46-48+0300 to 2020-07-11 17-21-10+0300.json\n",
      "('.files', 'last_snapshot 2020-07-10 00-15-35+0300.bak1') ('.files', 'last_snapshot 2020-07-10 00-15-35+0300.json')\n",
      "back patch 2020-07-10 00-15-35+0300 to 2020-07-10 20-46-48+0300.json\n"
     ]
    }
   ],
   "source": [
    "snap79_1 = patch_chain(lst,'2020-07-11 17-21-10+0300','2020-07-10 00-15-35+0300',snap81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T11:58:34.365897Z",
     "start_time": "2020-07-12T11:58:33.950874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snap81==snap81_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T12:00:16.553742Z",
     "start_time": "2020-07-12T12:00:16.155720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snap79==snap79_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
